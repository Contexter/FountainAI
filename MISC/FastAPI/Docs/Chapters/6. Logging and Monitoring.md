
# 6. Logging and Monitoring

Maintaining comprehensive **logging** and **monitoring** is critical for diagnosing issues, ensuring system health, and meeting security/audit requirements. This chapter outlines best practices and practical setups for collecting logs, metrics, and analytics across the **FountainAI** microservices.

---

## 1. Structured Logging

1. **JSON Format**  
   - Each service should log events in a structured format (e.g., JSON).  
   - Ensures logs can be parsed consistently by log aggregation tools (e.g., Elasticsearch, Splunk, or Grafana Loki).

2. **Minimal Sensitive Data**  
   - Avoid logging credentials, secrets, or PII (personally identifiable information).  
   - Redact or mask values wherever necessary.

3. **Contextual Fields**  
   - Include service name, timestamp, request ID (if available), log level, etc.  
   - This makes it easier to correlate requests across microservices.

4. **Log Levels**  
   - **DEBUG**: Verbose information for local debugging (avoid in production).  
   - **INFO**: General operational events (e.g., service startup, normal usage).  
   - **WARNING**: Potentially harmful situations or recoverable errors.  
   - **ERROR**: Errors that require action but may not crash the service.  
   - **CRITICAL**: Severe errors or fatal exceptions leading to a crash.

---

## 2. Centralized Log Aggregation

1. **Why Aggregate Logs?**  
   - With multiple microservices (KMS, Gateway, 2FA, etc.), local logs are fragmented.  
   - A centralized solution allows queries across **all** logs at once, simplifying root-cause analysis.

2. **Common Solutions**  
   - **ELK Stack** (Elasticsearch, Logstash, Kibana)  
   - **Graylog**  
   - **Grafana Loki** + **Promtail**  

3. **Implementation Steps**  
   - Deploy a logging agent (e.g., **Filebeat**, **Logstash**, **Promtail**) to each container or host that streams JSON logs to a collector.  
   - Configure Kibana or Grafana dashboards to search, filter, and visualize log data.

4. **Index Rotation**  
   - For large volumes of logs, set up index rotation (e.g., daily or weekly) to manage disk usage.  
   - Implement retention policies (e.g., keep logs for 90 days).

---

## 3. Metrics Collection (Prometheus)

1. **Prometheus Instrumentation**  
   - Each FastAPI service can integrate **`prometheus-fastapi-instrumentator`** to expose endpoint metrics like request count, latency, and error rates.  
   - Prometheus scrapes these metrics on a configurable interval.

2. **Common Metrics**  
   - **HTTP Requests**: Count, rate, latency, status codes.  
   - **Database Stats**: Connection count, query timings (if instrumented).  
   - **Custom Service Metrics**: e.g., how many OTPs generated by the 2FA service, or how many keys are active in the KMS.

3. **Docker Compose**  
   - Add a **prometheus** service to `docker-compose.yml`. Example snippet:

     ```yaml
     prometheus:
       image: prom/prometheus:latest
       container_name: prometheus
       volumes:
         - ./prometheus.yml:/etc/prometheus/prometheus.yml
       ports:
         - "9090:9090"
       networks:
         - app-network
       depends_on:
         - api_gateway
         - key_management_service
         - service_a
         - typesense_client_service
         - 2fa_service
     ```

4. **Prometheus Config**  
   - A basic `prometheus.yml` might include:

     ```yaml
     global:
       scrape_interval: 15s

     scrape_configs:
       - job_name: 'api_gateway'
         static_configs:
           - targets: ['api_gateway:8002']
       - job_name: 'key_management_service'
         static_configs:
           - targets: ['key_management_service:8003']
       - job_name: 'service_a'
         static_configs:
           - targets: ['service_a:8000']
       - job_name: 'typesense_client'
         static_configs:
           - targets: ['typesense_client_service:8001']
       - job_name: '2fa_service'
         static_configs:
           - targets: ['2fa_service:8004']
       - job_name: 'typesense'
         static_configs:
           - targets: ['typesense:8108']
     ```

   - Prometheus scrapes each service’s `/metrics` endpoint if exposed by **`prometheus-fastapi-instrumentator`**.

---

## 4. Dashboards and Alerting (Grafana)

1. **Grafana Setup**  
   - Deploy **Grafana** alongside Prometheus to visualize metrics on custom dashboards.  
   - Connect Grafana to your Prometheus server as a data source.

2. **Creating Dashboards**  
   - Build dashboards to track request rates, latency, error counts, CPU/memory usage, etc.  
   - For the 2FA Service, you might chart OTP generation and verification trends.

3. **Alerting Rules**  
   - Use either Grafana or Prometheus alerting to define rules (e.g., high error rates, latency spikes).  
   - Send notifications via email, Slack, PagerDuty, etc.

---

## 5. Tracing (Optional)

For deeper insights into request flows across services, consider **distributed tracing**:

- **Jaeger** or **Zipkin** can be integrated with FastAPI to capture end-to-end traces.  
- Useful for debugging performance bottlenecks or complex multi-service calls.

---

## 6. Practical Tips

1. **Consistent Log Levels**  
   - Standardize log levels across services to avoid confusion (e.g., use `INFO` and `ERROR` consistently).

2. **Log Request IDs**  
   - Generate a request ID at the API Gateway level and propagate it to downstream services via headers (e.g., `X-Request-Id`).  
   - Log this ID in each service to trace requests end-to-end.

3. **Health Check Endpoints**  
   - Maintain simple `/health` (or `/ready`) endpoints returning basic status.  
   - Docker Compose and Prometheus can rely on these for checks and scraping.

4. **Resource Monitoring**  
   - Collect container-level metrics (CPU, memory, disk I/O) with tools like **cAdvisor** + **Prometheus** node exporters to ensure none of the services are starved or overloaded.

---

## 7. Summary

**Logging and monitoring** are vital for maintaining a healthy microservice architecture. By centralizing logs, instrumenting each service with Prometheus metrics, and optionally adding distributed tracing, you gain full visibility into the FountainAI ecosystem’s performance and security posture.

**Next Steps**:  
Proceed to **`07_testing_the_ecosystem.md`** for guidance on testing—covering unit tests, integration tests, and end-to-end verification of the entire system.

---

**End of Chapter 6.**