
# 7. Testing the Ecosystem

Testing is critical to ensure the **FountainAI** microservices (KMS, API Gateway, 2FA Service, Typesense Client, Service A) function correctly together. A robust testing strategy covers:

1. **Unit Testing**: Verifying individual functions and components in isolation.  
2. **Integration Testing**: Ensuring multiple services interact correctly (e.g., Service A → Typesense Client).  
3. **End-to-End Testing**: Testing the entire flow from an external client’s perspective, passing through Caddy, the API Gateway, and down to the services.

---

## 1. Unit Tests

### 1.1 Scope
- Test individual modules (e.g., OTP generation in the 2FA Service, API key logic in the KMS).
- Mock external dependencies (database calls, HTTP requests to other services) to keep tests focused and fast.

### 1.2 Tools
- **`pytest`**: A popular Python testing framework.
- **`unittest.mock`** or **`pytest-mock`**: For mocking I/O operations and external calls.

### 1.3 Example
A typical **pytest** structure might look like:

```
2fa_service/
├── app/
│   ├── ...
│   └── tests/
│       ├── __init__.py
│       └── test_otp_service.py
```

**Sample** `test_otp_service.py`:
```python
import pytest
from unittest.mock import MagicMock
from app.services.otp_service import OTPService
from app.models import User

def test_generate_otp_success(db_session):
    # Setup
    user = User(username="testuser", otp_enabled=True, otp_secret="TESTSECRET")
    db_session.add(user)
    db_session.commit()

    otp_service = OTPService()

    # Execute
    otp_log = otp_service.generate_otp("testuser", db_session)

    # Verify
    assert otp_log.otp_code is not None
    assert otp_log.verified is False

def test_generate_otp_no_user(db_session):
    otp_service = OTPService()
    with pytest.raises(Exception) as exc_info:
        otp_service.generate_otp("nonexistent_user", db_session)
    assert "User not found or 2FA not enabled" in str(exc_info.value)
```

---

## 2. Integration Tests

### 2.1 Scope
- Validate interactions between **two or more** microservices, e.g., KMS issuing tokens for the API Gateway, or Service A calling the Typesense Client to sync data.

### 2.2 Tools
- **`pytest`** or **`pytest-docker`**: Can spin up real containers for integration.  
- **`requests`** or **`httpx`**: Make actual HTTP calls between services.

### 2.3 Example Flow
1. Start `docker-compose` in a **test** environment (e.g., `docker-compose -f docker-compose.test.yml up -d`).  
2. **Wait** until all services are healthy.  
3. **Test** by registering a user in the KMS, retrieving a JWT, calling the API Gateway, verifying responses from Service A or the 2FA Service.  
4. **Assert** on HTTP status codes, response payloads, log entries, or DB states.

**Pseudocode**:
```python
def test_kms_api_gateway_integration():
    # 1. Register a user in KMS
    response = requests.post("http://localhost:8003/register", json={
      "username": "testadmin",
      "password": "secure123",
      "roles": "admin"
    })
    assert response.status_code == 201

    # 2. Login to get JWT
    response = requests.post("http://localhost:8003/login", json={
      "username": "testadmin",
      "password": "secure123"
    })
    assert response.status_code == 200
    token_data = response.json()
    token = token_data["access_token"]

    # 3. Call API Gateway with JWT
    headers = {"Authorization": f"Bearer {token}"}
    resp = requests.get("http://localhost:8002/health", headers=headers)
    assert resp.status_code == 200
    assert resp.json() == {"status": "healthy"}
```

---

## 3. End-to-End Testing

### 3.1 Scope
- Test from a client’s perspective, typically hitting **Caddy** on port **443** or **80**.
- Ensures TLS termination, domain routing, and each microservice path is correct.

### 3.2 Example End-to-End Scenarios
1. **User Login + 2FA**  
   - Client registers a user with the KMS, obtains a JWT.  
   - The user has 2FA enabled → calls 2FA Service `/auth/generate` → enters OTP → calls `/auth/verify`.  
   - The API Gateway only allows certain operations after the OTP is verified.

2. **Service A Sequence and Search**  
   - Creates a new element via `http://yourdomain.com/service_a/sequence`.  
   - Confirms the new element is indexed in Typesense by calling `http://yourdomain.com/typesense_client/search`.

3. **API Key Rotation**  
   - Admin user rotates an API key in the KMS → ensures old key no longer works, new key does.

### 3.3 Tools
- **Postman** or **Newman** for scripting E2E tests.  
- **Cypress** or **Playwright** if there’s a frontend involved.

---

## 4. Test Automation

### 4.1 CI/CD
- Integrate tests into a pipeline (GitHub Actions, GitLab CI, Jenkins).  
- On each commit/pull request:
  1. **Build** Docker images  
  2. **Spin up** the environment with Compose  
  3. **Run** unit/integration tests  
  4. **Destroy** the environment

### 4.2 Dev vs. Staging vs. Production
- **Dev**: Frequent merges, quick feedback on small changes.  
- **Staging**: Full environment mirroring production scale, used for final integration and performance tests.  
- **Production**: Only run critical checks; any code reaching here should have passed dev + staging tests.

---

## 5. Troubleshooting & Best Practices

1. **Clear Logs**  
   - For multi-service debugging, always check logs from the gateway, 2FA, and KMS.  
2. **Mocking External Services**  
   - For local integration tests, you might mock Twilio or SMTP calls so as not to send real OTP messages.  
3. **Test Data Cleanup**  
   - Use ephemeral databases or reset them after each test to avoid leftover data confusion.  
4. **Performance Testing**  
   - Tools like **Locust** or **JMeter** can stress test the entire system under load.

---

## 6. Summary

A **comprehensive testing strategy** ensures your FountainAI microservices interoperate correctly, remain stable under changes, and provide the expected user experience. By combining **unit**, **integration**, and **end-to-end** tests—and automating them in a CI/CD pipeline—you’ll maintain a high-quality codebase and reliably deploy new features.

**Next Steps**:  
Proceed to **`08_conclusion.md`** for a final wrap-up and future expansion directions.

---

**End of Chapter 7.**